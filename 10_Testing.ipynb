{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_Testing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sosmany1/CLIP_Steering/blob/main/10_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjwE9yv-7M3z",
        "outputId": "b7053334-3d65-4925-9870-a1d717fbda62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# mount files from google drive\n",
        "# and follow the steps here\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount files from google drive\n",
        "# and follow the steps here\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRXVQ4rF7bmi",
        "outputId": "95c2d31e-2d4e-4a42-a333-9742df31e4d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gp4qs3oe7dD-",
        "outputId": "a8e3b956-e390-4fb3-f8d9-420d7f9217c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !git clone https://github.com/sosmany1/CLIP_Steering.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stowAl4F7gDk",
        "outputId": "620b85ee-03b6-4698-de14-32db4d042b80"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CLIP_Steering'...\n",
            "remote: Enumerating objects: 230, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 230 (delta 1), reused 0 (delta 0), pack-reused 223\u001b[K\n",
            "Receiving objects: 100% (230/230), 9.12 MiB | 26.53 MiB/s, done.\n",
            "Resolving deltas: 100% (109/109), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! echo $PYTHONPATH\n",
        "%env PYTHONPATH=\"$/env/python:/content/CLIP_Steering/projects/styleGAN2/stylegan2-ada-pytorch/\"\n",
        "!echo $PYTHONPATH\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqKNCVel7Tnj",
        "outputId": "fde0916b-4143-4846-9e2a-acbad5a0c497"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/env/python\n",
            "env: PYTHONPATH=\"$/env/python:/content/CLIP_Steering/projects/styleGAN2/stylegan2-ada-pytorch/\"\n",
            "\"$/env/python:/content/CLIP_Steering/projects/styleGAN2/stylegan2-ada-pytorch/\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSTLC-yD7pxn",
        "outputId": "67ad0afa-c54d-43fe-aa0d-9a8a3f33a89e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr 22 06:53:36 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch==1.7.1 torchvision==0.8.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXEccRKj7sig",
        "outputId": "a0818728-1380-454c-8e26-7d83d407fe73"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8 MB 18 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2\n",
            "  Downloading torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 47.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1) (1.21.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.7.1 torchvision-0.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/CLIP.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saxXqTUr7y-M",
        "outputId": "ce0da49f-d41a-447a-ec52-ccc59f6ca71c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-0gsqyxwa\n",
            "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-0gsqyxwa\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.64.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.7.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.8.2)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->clip==1.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->clip==1.0) (4.1.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (7.1.2)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369389 sha256=ceb162f37bd0e910eb380551bdc103656135b67b3552d63ae6cffa6361452101\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hipj08ld/wheels/fd/b9/c3/5b4470e35ed76e174bff77c92f91da82098d5e35fd5bc8cdac\n",
            "Successfully built clip\n",
            "Installing collected packages: ftfy, clip\n",
            "Successfully installed clip-1.0 ftfy-6.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGm8t1Fw72f4",
        "outputId": "4de3403e-4090-4269-8a28-5b1a64e452a4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n",
            "Collecting pyspng\n",
            "  Downloading pyspng-0.1.0-cp37-cp37m-manylinux2010_x86_64.whl (195 kB)\n",
            "\u001b[K     |████████████████████████████████| 195 kB 9.6 MB/s \n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 52.1 MB/s \n",
            "\u001b[?25hCollecting imageio-ffmpeg==0.4.3\n",
            "  Downloading imageio_ffmpeg-0.4.3-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.9 MB 83.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyspng) (1.21.6)\n",
            "Installing collected packages: pyspng, ninja, imageio-ffmpeg\n",
            "Successfully installed imageio-ffmpeg-0.4.3 ninja-1.10.2.3 pyspng-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ftfy regex tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p056HnA-8aGD",
        "outputId": "a8919c48-27cd-4bde-e7d4-5a953147652f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (6.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n"
      ],
      "metadata": {
        "id": "hK9xVYMNCE6B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adedddc8-c450-4ed5-b818-6265766f13e3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd CLIP_Steering//projects/styleGAN2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RczLaNzT77En",
        "outputId": "4dd3b4e5-3e12-4ad2-90ab-ead6b12d6169"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CLIP_Steering/projects/styleGAN2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZPYfBuT77z5",
        "outputId": "ad18a3e4-68c7-4617-ce12-1f56d80057dd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan2-ada-pytorch'...\n",
            "remote: Enumerating objects: 128, done.\u001b[K\n",
            "remote: Total 128 (delta 0), reused 0 (delta 0), pack-reused 128\u001b[K\n",
            "Receiving objects: 100% (128/128), 1.12 MiB | 24.95 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DrLK_tK8TA7",
        "outputId": "ed99191d-dd99-4c6b-91a4-132cf688a6de"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CLIP_Steering/projects\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR5eqHEz8U9_",
        "outputId": "8ec89ebb-cdbf-4ba0-9577-226b59aee6ac"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CLIP_Steering\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import clip\n",
        "clip.available_models()\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "54u4ocvh8EvM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import clip\n",
        "clip.available_models()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e7VAd_w8PQI",
        "outputId": "075cc308-e085-4c4f-a419-8dfe3c6b2c14"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RN50',\n",
              " 'RN101',\n",
              " 'RN50x4',\n",
              " 'RN50x16',\n",
              " 'RN50x64',\n",
              " 'ViT-B/32',\n",
              " 'ViT-B/16',\n",
              " 'ViT-L/14',\n",
              " 'ViT-L/14@336px']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjArhDuY8j8R",
        "outputId": "2fd426e6-7262-4743-a225-6e75816ece2a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clip\t  data\t   MANIFEST.in\t  notebooks  README.md\t       setup.py\n",
            "CLIP.png  LICENSE  model-card.md  projects   requirements.txt  tests\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device, jit=False)\n",
        "\n",
        "\n",
        "image = preprocess(Image.open(\"/content/CLIP_Steering/CLIP.png\")).unsqueeze(0).to(device)\n",
        "text = clip.tokenize([\"a diagram\", \"a dog\", \"a cat\"]).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    image_features = model.encode_image(image)\n",
        "    text_features = model.encode_text(text)\n",
        "    \n",
        "    logits_per_image, logits_per_text = model(image, text)\n",
        "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
        "\n",
        "print(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421068 0.00299572]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFKIURnJ8kuT",
        "outputId": "a389f203-82c8-41ee-ccc5-14f998f23704"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 338M/338M [00:10<00:00, 33.2MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label probs: [[0.9927   0.004185 0.002968]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI6K3M85xQNh",
        "outputId": "5c5acf33-5c1b-4bfe-de65-cb7bf566a74e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-utils\n",
            "  Downloading torch-utils-0.1.2.tar.gz (4.9 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torch-utils) (1.7.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torch-utils) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->torch-utils) (1.21.6)\n",
            "Building wheels for collected packages: torch-utils\n",
            "  Building wheel for torch-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-utils: filename=torch_utils-0.1.2-py3-none-any.whl size=6202 sha256=91de8d04aba980a29e6f31a2b934ca272dedf003e45701ea0ed7a98ce58416ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/c0/1d/a539c1c2a4d41c5d7109899289cded24fe1320b6a6c7b02a4c\n",
            "Successfully built torch-utils\n",
            "Installing collected packages: torch-utils\n",
            "Successfully installed torch-utils-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_utils"
      ],
      "metadata": {
        "id": "jZKK-onWxWLq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "QKEsZTTZxY8e"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ls ~/.cache/clip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtxguzLD8rcP",
        "outputId": "46141469-2b9d-49fb-d244-09c26a800016"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ViT-B-32.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The clip model is downloaded into the cache. Make sure to change the ganalyze_with_clip.py and generation_demo3.py to point to the cache via '/root/.cache/clip/ViT-B-32.pt' . You can also use '~/.cache/clip/ViT-B-32.pt'"
      ],
      "metadata": {
        "id": "LTl_asuE8sg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! echo $PYTHONPATH\n",
        "%env PYTHONPATH=\"$/env/python:/content/CLIP_Steering/projects/styleGAN2/stylegan2-ada-pytorch/\"\n",
        "! echo $PYTHONPATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55-S8ded9cHx",
        "outputId": "dc24e894-0f9e-4d02-d874-77ba3811de46"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"$/env/python:/content/CLIP_Steering/projects/styleGAN2/stylegan2-ada-pytorch/\"\n",
            "env: PYTHONPATH=\"$/env/python:/content/CLIP_Steering/projects/styleGAN2/stylegan2-ada-pytorch/\"\n",
            "\"$/env/python:/content/CLIP_Steering/projects/styleGAN2/stylegan2-ada-pytorch/\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. For now drag and drop all ganalyze and other files in the folder into the stylegan2-ada-pytorch folder. Will fix later"
      ],
      "metadata": {
        "id": "9dcI4T-59rk4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. From stylegan2 pytorch github repo, download the pretrained ffhq.pkl model and store it in your google drive. Here my ffhq.pkl file is given by path /content/drive/MyDrive/Colab Notebooks/ffhq_model/ffhq.pkl\n",
        "##3. Make sure to change this path in the ganalyze_with_clip.py and generation_demo3.py file. Will fix later"
      ],
      "metadata": {
        "id": "3bRTgJPm-lX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Change path in clip_classifier_utils.py line 58 to /content/CLIP_Steering/clip/bpe_simple_vocab_16e6.txt.gz"
      ],
      "metadata": {
        "id": "vusl3TtWDYXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/CLIP_Steering/projects/styleGAN2/stylegan2-ada-pytorch/ganalyze_with_clip.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePqWlZIDyf9s",
        "outputId": "7aed23a8-5d37-4a00-bbd1-a167f130413a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters: 151,277,313\n",
            "Input resolution: 224\n",
            "Context length: 77\n",
            "Vocab size: 49408\n",
            "\n",
            "approach:  one_direction\n",
            "\n",
            "tcmalloc: large alloc 1638400000 bytes == 0x5585636a2000 @  0x7fce3c2261e7 0x7fce39af70ce 0x7fce39b4dcf5 0x7fce39b4df4f 0x7fce39bf0673 0x7fce3354cb39 0x7fce339b7d7d 0x5584d69ff160 0x5584d6af0d4d 0x5584d6a72ec8 0x5584d6a6da2e 0x5584d6a00f21 0x5584d6a01341 0x5584d6a6fff1 0x5584d6a6da2e 0x5584d6a0088a 0x5584d6a6f719 0x5584d6a6da2e 0x5584d6a0088a 0x5584d6a72d30 0x5584d6a6da2e 0x5584d6a6d723 0x5584d6b37812 0x5584d6b37b8d 0x5584d6b37a36 0x5584d6b0f183 0x5584d6b0ee2c 0x7fce3b010c87 0x5584d6b0ed0a\n",
            "tcmalloc: large alloc 1638400000 bytes == 0x5585c5122000 @  0x7fce3c228001 0x7fce39af71af 0x7fce39b515f4 0x7fce39b51b09 0x7fce39b53620 0x7fce39b53d1b 0x7fce39bf561c 0x5584d69ff11c 0x5584d69feef0 0x5584d6a7364d 0x5584d6a6da2e 0x5584d6a0088a 0x5584d6a6e8f6 0x5584d6a6da2e 0x5584d6a0088a 0x5584d6a6f719 0x5584d6a6dcdd 0x5584d6a00f21 0x5584d6a44579 0x5584d6a01341 0x5584d6a6fff1 0x5584d6a6dcdd 0x5584d6a0088a 0x5584d6a6e8f6 0x5584d6a00ce9 0x5584d6a01341 0x5584d6a6fff1 0x5584d6a6da2e 0x5584d6a00f21 0x5584d6a01341 0x5584d6a6fff1\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUhyHJk-_RbS",
        "outputId": "41df043e-0a9e-4a32-8162-7c53c7719ee3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CLIP_Steering\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd CLIP_Steering"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sx6PI6E0ovf",
        "outputId": "2c05475b-f90f-4b1e-9732-415fcac30e48"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CLIP_Steering\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import clip\n",
        "from PIL import Image\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
        "\n",
        "print(model)\n",
        "\n",
        "image = preprocess(Image.open(\"CLIP.png\")).unsqueeze(0).to(device)\n",
        "text = clip.tokenize([\"a diagram\", \"a dog\", \"a cat\"]).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    image_features = model.encode_image(image)\n",
        "    text_features = model.encode_text(text)\n",
        "    \n",
        "    logits_per_image, logits_per_text = model(image, text)\n",
        "    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n",
        "\n",
        "print(\"Label probs:\", probs)  # prints: [[0.9927937  0.00421068 0.00299572]]"
      ],
      "metadata": {
        "id": "_1q2ghZG_Ud9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import CLIP"
      ],
      "metadata": {
        "id": "UIaw1CRr_dsB"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create an \"out\" director within stylegan-ada-pytorch folder where results from the below pretrained networks will be saved \n"
      ],
      "metadata": {
        "id": "Hcx__hgWEjMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/CLIP_Steering/projects/styleGAN2/stylegan2-ada-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brQq667LEYNK",
        "outputId": "95a13c30-d70a-4829-b3b2-7e88fe34f7f8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CLIP_Steering/projects/styleGAN2/stylegan2-ada-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir out"
      ],
      "metadata": {
        "id": "t6SCnfyREZXx"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohpjiI-HEdgQ",
        "outputId": "3e25fc05-2fd0-4310-e39a-bbe551addaab"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;32mcalc_metrics.py\u001b[0m*          ganalyze_transformations.py  \u001b[01;34mmetrics\u001b[0m/\n",
            "clip_classifier_utils.py  ganalyze_with_clip.py        \u001b[01;34mout\u001b[0m/\n",
            "\u001b[01;32mdataset_tool.py\u001b[0m*          \u001b[01;32mgenerate.py\u001b[0m*                 \u001b[01;32mprojector.py\u001b[0m*\n",
            "\u001b[01;34mdnnlib\u001b[0m/                   generation_demo3.py          \u001b[01;32mREADME.md\u001b[0m*\n",
            "\u001b[01;32mDockerfile\u001b[0m*               generation_demo.ipynb        \u001b[01;32mstyle_mixing.py\u001b[0m*\n",
            "\u001b[01;32mdocker_run.sh\u001b[0m*            __init__.py                  \u001b[01;34mtorch_utils\u001b[0m/\n",
            "\u001b[01;34mdocs\u001b[0m/                     \u001b[01;32mlegacy.py\u001b[0m*                   \u001b[01;34mtraining\u001b[0m/\n",
            "ganalyze_common_utils.py  \u001b[01;32mLICENSE.txt\u001b[0m*                 \u001b[01;32mtrain.py\u001b[0m*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate curated MetFaces images without truncation (Fig.10 left)\n",
        "!python /content/CLIP_Steering/projects/styleGAN2/stylegan2-ada-pytorch/generate.py --outdir=out --trunc=1 --seeds=85,265,297,849 \\\n",
        "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metfaces.pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i9ij_FuE6cM",
        "outputId": "544a895e-4702-4179-c669-40b7048456ee"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading networks from \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metfaces.pkl\"...\n",
            "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metfaces.pkl ... done\n",
            "Generating image for seed 85 (0/4) ...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "Generating image for seed 265 (1/4) ...\n",
            "Generating image for seed 297 (2/4) ...\n",
            "Generating image for seed 849 (3/4) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate uncurated MetFaces images with truncation (Fig.12 upper left)\n",
        "!python /content/CLIP_Steering/projects/styleGAN2/stylegan2-ada-pytorch/generate.py --outdir=out --trunc=0.7 --seeds=600-605 \\\n",
        "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metfaces.pkl"
      ],
      "metadata": {
        "id": "fnywuCwVE-sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate class conditional CIFAR-10 images (Fig.17 left, Car)\n",
        "!python /content/CLIP_Steering/projects/styleGAN2/stylegan2-ada-pytorch/generate.py --outdir=out --seeds=0-35 --class=1 \\\n",
        "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/cifar10.pkl"
      ],
      "metadata": {
        "id": "tM4bYZJJFBec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Style mixing example\n",
        "!python /content/CLIP_Steering/projects/styleGAN2/stylegan2-ada-pytorch/style_mixing.py --outdir=out --rows=85,100,75,458,1500 --cols=55,821,1789,293 \\\n",
        "    --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metfaces.pkl!"
      ],
      "metadata": {
        "id": "PamFN4g-FHeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "iJAfYyZJFKY3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezye9Ob4FaTD",
        "outputId": "9b1ebec6-4f05-4591-e2e4-07dc92d01b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CLIP_Steering/projects/styleGAN2/stylegan2-ada-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download directly from url into the stylegan2-ada-pytorch folder\n",
        "!wget https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpgO69TfFaKW",
        "outputId": "7e7e22d2-105a-4bbb-a506-7cfde53dab02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-22 02:59:33--  https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\n",
            "Resolving nvlabs-fi-cdn.nvidia.com (nvlabs-fi-cdn.nvidia.com)... 52.84.251.102, 52.84.251.108, 52.84.251.69, ...\n",
            "Connecting to nvlabs-fi-cdn.nvidia.com (nvlabs-fi-cdn.nvidia.com)|52.84.251.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 381624121 (364M) [binary/octet-stream]\n",
            "Saving to: ‘ffhq.pkl’\n",
            "\n",
            "ffhq.pkl            100%[===================>] 363.94M   218MB/s    in 1.7s    \n",
            "\n",
            "2022-04-22 02:59:35 (218 MB/s) - ‘ffhq.pkl’ saved [381624121/381624121]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d7xenKeZgix",
        "outputId": "a5f8f3cd-014b-4d16-afef-bcc66999ccb7"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CLIP_Steering/projects/styleGAN2/stylegan2-ada-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python /content/CLIP_Steering/projects/styleGAN2/stylegan2-ada-pytorch/ganalyze_with_clip.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRhTEykuhR5a",
        "outputId": "f24ac243-34eb-437f-cffb-6f845a0fb60c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters: 151,277,313\n",
            "Input resolution: 224\n",
            "Context length: 77\n",
            "Vocab size: 49408\n",
            "\n",
            "approach:  one_direction\n",
            "\n",
            "tcmalloc: large alloc 1638400000 bytes == 0x558ead3e0000 @  0x7f27ab1671e7 0x7f27a8a380ce 0x7f27a8a8ecf5 0x7f27a8a8ef4f 0x7f27a8b31673 0x7f27a248db39 0x7f27a28f8d7d 0x558e1f279160 0x558e1f36ad4d 0x558e1f2ecec8 0x558e1f2e7a2e 0x558e1f27af21 0x558e1f27b341 0x558e1f2e9ff1 0x558e1f2e7a2e 0x558e1f27a88a 0x558e1f2e9719 0x558e1f2e7a2e 0x558e1f27a88a 0x558e1f2ecd30 0x558e1f2e7a2e 0x558e1f2e7723 0x558e1f3b1812 0x558e1f3b1b8d 0x558e1f3b1a36 0x558e1f389183 0x558e1f388e2c 0x7f27a9f51c87 0x558e1f388d0a\n",
            "tcmalloc: large alloc 1638400000 bytes == 0x558f0ee60000 @  0x7f27ab169001 0x7f27a8a381af 0x7f27a8a925f4 0x7f27a8a92b09 0x7f27a8a94620 0x7f27a8a94d1b 0x7f27a8b3661c 0x558e1f27911c 0x558e1f278ef0 0x558e1f2ed64d 0x558e1f2e7a2e 0x558e1f27a88a 0x558e1f2e88f6 0x558e1f2e7a2e 0x558e1f27a88a 0x558e1f2e9719 0x558e1f2e7cdd 0x558e1f27af21 0x558e1f2be579 0x558e1f27b341 0x558e1f2e9ff1 0x558e1f2e7cdd 0x558e1f27a88a 0x558e1f2e88f6 0x558e1f27ace9 0x558e1f27b341 0x558e1f2e9ff1 0x558e1f2e7a2e 0x558e1f27af21 0x558e1f27b341 0x558e1f2e9ff1\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python /content/CLIP_Steering/projects/styleGAN2/stylegan2-ada-pytorch/ganalyze_transformations.py\n"
      ],
      "metadata": {
        "id": "THXCbJJthSe3"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ipython /content/CLIP_Steering/projects/styleGAN2/stylegan2-ada-pytorch/generation_demo3.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlKtMDE5iDAX",
        "outputId": "ac183918-d488-49bf-b0a8-bb71c261e4b9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TerminalIPythonApp] WARNING | GUI event loop or pylab initialization failed\n",
            "\u001b]0;IPython: styleGAN2/stylegan2-ada-pytorch\u0007\u001b[0;31m\u001b[0m\n",
            "\u001b[0;31mUnknownBackend\u001b[0mTraceback (most recent call last)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36menable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n",
            "\u001b[1;32m   2953\u001b[0m         \u001b[0;31m# Now we must activate the gui pylab wants to use, and fix %run to take\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   2954\u001b[0m         \u001b[0;31m# plot updates into account\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m-> 2955\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_gui\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m   2956\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagics_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ExecutionMagics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_runner\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   2957\u001b[0m             \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmpl_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_execfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/terminal/interactiveshell.py\u001b[0m in \u001b[0;36menable_gui\u001b[0;34m(self, gui)\u001b[0m\n",
            "\u001b[1;32m    512\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    513\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_eventloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputhook\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 514\u001b[0;31m                 \u001b[0mget_inputhook_name_and_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    516\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_eventloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/terminal/pt_inputhooks/__init__.py\u001b[0m in \u001b[0;36mget_inputhook_name_and_func\u001b[0;34m(gui)\u001b[0m\n",
            "\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mUnknownBackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maliases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;31mUnknownBackend\u001b[0m: No event loop integration for 'inline'. Supported event loops are: qt, qt4, qt5, gtk, gtk2, gtk3, tk, wx, pyglet, glut, osx\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "0 255\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n",
            "Model parameters: 151,277,313\n",
            "Input resolution: 224\n",
            "Context length: 77\n",
            "Vocab size: 49408\n",
            "Done: 0 / 1000\n",
            "Done: 200 / 1000\n",
            "Done: 400 / 1000\n",
            "Done: 600 / 1000\n",
            "Done: 800 / 1000\n",
            "Where is the image????\n",
            "['an evil face', 'a radiant face', 'a criminal face', 'a beautiful face', 'a handsome face', 'a smart face']\n",
            "[[0.23495597]\n",
            " [0.20812452]\n",
            " [0.22891992]\n",
            " [0.22199535]\n",
            " [0.19632639]\n",
            " [0.20789139]]\n",
            "an evil face\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AWAutZR_iSgH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}